<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>RAG Testing Site – Fictional Knowledge Base</title>
    <style>
        body {
            font-family: Arial, Helvetica, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 40px auto;
            padding: 0 20px;
            color: #222;
        }

        header {
            border-bottom: 2px solid #ddd;
            margin-bottom: 30px;
            padding-bottom: 10px;
        }

        h1, h2, h3 {
            color: #003366;
        }

        .warning {
            background: #fff3cd;
            border: 1px solid #ffeeba;
            padding: 15px;
            margin: 20px 0;
        }

        section {
            margin-bottom: 40px;
        }

        footer {
            border-top: 1px solid #ddd;
            margin-top: 40px;
            padding-top: 20px;
            font-size: 0.9em;
            color: #555;
        }

        code {
            background: #f4f4f4;
            padding: 2px 5px;
            border-radius: 4px;
        }
    </style>
</head>
<body>

<header>
    <h1>AI RAG Testing Website</h1>
    <p>
        This website is a <strong>fictional knowledge base</strong> created exclusively
        for testing <strong>Retrieval-Augmented Generation (RAG)</strong> systems.
    </p>
</header>

<div class="warning">
    <strong>Important:</strong>
    <ul>
        <li>All people, companies, technologies, and facts on this page are <strong>entirely fictional</strong>.</li>
        <li>This content should <strong>not</strong> be treated as real-world information.</li>
        <li>The sole purpose is to evaluate document ingestion, chunking, retrieval, and grounding.</li>
    </ul>
</div>

<section>
    <h2>Overview of the Fictional Domain</h2>
    <p>
        The fictional domain described here revolves around a company called
        <strong>Orion Analytics Group (OAG)</strong>, a research lab focused on experimental
        artificial intelligence systems. OAG operates in the imaginary city of
        <strong>Nova Cascadia</strong>.
    </p>
    <p>
        OAG is known for developing internal tools that combine symbolic reasoning,
        vector-based retrieval, and narrative-driven datasets.
    </p>
</section>

<section>
    <h2>Fictional Company: Orion Analytics Group</h2>
    <p>
        Orion Analytics Group was founded in <strong>2031</strong> by
        <strong>Dr. Helena Voss</strong>, a fictional AI researcher.
    </p>
    <p>
        The company has three internal departments:
    </p>
    <ul>
        <li><strong>Astra Division</strong> – Focuses on data ingestion and embeddings.</li>
        <li><strong>Kepler Division</strong> – Responsible for retrieval pipelines and ranking algorithms.</li>
        <li><strong>Atlas Division</strong> – Handles evaluation, hallucination detection, and grounding metrics.</li>
    </ul>
</section>

<section>
    <h2>Fictional Technology: LUMA Index</h2>
    <p>
        The <strong>LUMA Index</strong> is a proprietary scoring system created by OAG.
        It measures how accurately an AI system answers questions using retrieved context.
    </p>
    <p>
        The LUMA Index is calculated using three fictional factors:
    </p>
    <ol>
        <li><strong>Context Alignment Score (CAS)</strong></li>
        <li><strong>Retrieval Precision Factor (RPF)</strong></li>
        <li><strong>Answer Grounding Coefficient (AGC)</strong></li>
    </ol>
    <p>
        A LUMA Index above <code>0.82</code> is considered acceptable for internal testing,
        while anything below <code>0.70</code> triggers a manual review.
    </p>
</section>

<section>
    <h2>Fictional Event: The Nova Cascadia Incident</h2>
    <p>
        In <strong>2034</strong>, OAG experienced what is now known as the
        <strong>Nova Cascadia Incident</strong>.
    </p>
    <p>
        During this event, an experimental RAG system incorrectly merged documents
        from the Astra and Atlas divisions, resulting in contradictory answers being
        presented as facts.
    </p>
    <p>
        This incident led to the creation of stricter retrieval boundaries and the
        introduction of synthetic contradiction tests.
    </p>
</section>

<section>
    <h2>Sample Facts for Retrieval Testing</h2>
    <ul>
        <li>Orion Analytics Group is headquartered in Nova Cascadia.</li>
        <li>The Astra Division focuses on embeddings and data ingestion.</li>
        <li>The Kepler Division designs retrieval and ranking algorithms.</li>
        <li>The Atlas Division evaluates hallucinations and grounding.</li>
        <li>The LUMA Index considers CAS, RPF, and AGC.</li>
        <li>The Nova Cascadia Incident occurred in 2034.</li>
    </ul>
</section>

<section>
    <h2>Intended RAG Testing Use Cases</h2>
    <p>
        This page can be used to test:
    </p>
    <ul>
        <li>Document chunking strategies</li>
        <li>Semantic vs keyword retrieval</li>
        <li>Grounded question answering</li>
        <li>Multi-hop retrieval (e.g., incident → division → metric)</li>
        <li>Hallucination detection when answers are not present</li>
    </ul>
</section>

<footer>
    <p>
        © Fictional Content for AI Testing Only<br />
        Hosted as a static page for GitHub Pages demonstrations.
    </p>
</footer>

</body>
</html>
